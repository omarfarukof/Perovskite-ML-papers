{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e30a24",
   "metadata": {},
   "source": [
    "- **GPU Acceleration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856764fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cuml.accel\n",
    "# cuml.accel.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f604d6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba611bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, matthews_corrcoef)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from dd_hybrid_sampler import DDHybridSampler\n",
    "from cost_sensitive import OverBoostClassifier\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c1f53",
   "metadata": {},
   "source": [
    "# Dataset Listing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf83504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path: Path):\n",
    "    if path.suffix == \".csv\":\n",
    "        return pd.read_csv(path)\n",
    "    else:                       # Excel\n",
    "        return pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d09d7",
   "metadata": {},
   "source": [
    "- Dataset path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e5075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR   = Path(\"Imbalanced_datasets\") / \"binary\"         # CSV files\n",
    "CSV_FILES  = sorted(DATA_DIR.glob(\"*.csv\"))\n",
    "assert CSV_FILES, \"No CSV found\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ae837",
   "metadata": {},
   "source": [
    "- Result save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca653274",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = pathlib.Path(\"output\") / \"binary\"  \n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf19c3",
   "metadata": {},
   "source": [
    "- All avalable datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2421b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 BigML_Dataset.csv\n",
      "1 MBA.csv\n",
      "2 Satimage.csv\n",
      "3 abalone-17_vs_7-8-9-10.csv\n",
      "4 abalone-19_vs_10-11-12-13.csv\n",
      "5 abalone-20_vs_8-9-10.csv\n",
      "6 abalone.csv\n",
      "7 abalone19.csv\n",
      "8 abalone_20.csv\n",
      "9 brain_stroke.csv\n",
      "10 breast_cancer_wisconsin.csv\n",
      "11 car_good.csv\n",
      "12 cervical.csv\n",
      "13 cirrhosis.csv\n",
      "14 cleveland-0_vs_4.csv\n",
      "15 compile_level_01.csv\n",
      "16 df_train1.csv\n",
      "17 diabetes.csv\n",
      "18 ecoli-0-1-4-7_vs_2-3-5-6.csv\n",
      "19 ecoli-0-1-4-7_vs_5-6.csv\n",
      "20 ecoli-0-2-3-4_vs_5.csv\n",
      "21 ecoli-0-2-6-7_vs_3-5.csv\n",
      "22 ecoli-0-3-4-6_vs_5.csv\n",
      "23 ecoli-0-3-4-7_vs_5-6.csv\n",
      "24 ecoli-0-3-4_vs_5.csv\n",
      "25 ecoli-0-4-6_vs_5.csv\n",
      "26 ecoli-0-6-7_vs_3-5.csv\n",
      "27 ecoli-0-6-7_vs_5.csv\n",
      "28 ecoli-0_vs_1.csv\n",
      "29 ecoli2.csv\n",
      "30 ecoli3.csv\n",
      "31 ecoli4.csv\n",
      "32 ecoli_013vs26.csv\n",
      "33 flaref.csv\n",
      "34 glass-0-1-4-6_vs_2.csv\n",
      "35 glass-0-1-5_vs_2.csv\n",
      "36 glass-0-1-6_vs_2.csv\n",
      "37 glass-0-1-6_vs_5.csv\n",
      "38 glass-0-4_vs_5.csv\n",
      "39 glass-0-6_vs_5.csv\n",
      "40 glass0.csv\n",
      "41 glass1.csv\n",
      "42 glass2.csv\n",
      "43 glass4.csv\n",
      "44 glass6.csv\n",
      "45 hcv_binary_mice.csv\n",
      "46 hcv_data_binary.csv\n",
      "47 hf.csv\n",
      "48 ionosphere.csv\n",
      "49 iris0.csv\n",
      "50 kddcup-land_vs_portsweep.csv\n",
      "51 kddcup-land_vs_satan.csv\n",
      "52 kddr_rookkit.csv\n",
      "53 led7digit-0-2-4-5-6-7-8-9_vs_1.csv\n",
      "54 mi_lethal_2.csv\n",
      "55 new-thyroid1.csv\n",
      "56 page-blocks-1-3_vs_4.csv\n",
      "57 page-blocks0.csv\n",
      "58 page.csv\n",
      "59 perov_form.csv\n",
      "60 perov_stab.csv\n",
      "61 phishing_uci.csv\n",
      "62 pima.csv\n",
      "63 poker-8-9_vs_5.csv\n",
      "64 poker-8-9_vs_6.csv\n",
      "65 poker_86.csv\n",
      "66 seg.csv\n",
      "67 shuttle-2_vs_5.csv\n",
      "68 shuttle-6_vs_2-3.csv\n",
      "69 shuttle-c0-vs-c4.csv\n",
      "70 shuttle-c2-vs-c4.csv\n",
      "71 spect_heart.csv\n",
      "72 transfusion.csv\n",
      "73 vehicle0.csv\n",
      "74 vehicle1.csv\n",
      "75 vehicle2.csv\n",
      "76 vehicle3.csv\n",
      "77 vowel.csv\n",
      "78 wine.csv\n",
      "79 winequality-red-3_vs_5.csv\n",
      "80 winequality-red-8_vs_6-7.csv\n",
      "81 winequality-red-8_vs_6.csv\n",
      "82 winequality-white-3-9_vs_5.csv\n",
      "83 winequality-white-3_vs_7.csv\n",
      "84 winequality_white.csv\n",
      "85 wisconsin.csv\n",
      "86 yeast-0-2-5-6_vs_3-7-8-9.csv\n",
      "87 yeast-0-2-5-7-9_vs_3-6-8.csv\n",
      "88 yeast-0-3-5-9_vs_7-8.csv\n",
      "89 yeast-1-4-5-8_vs_7.csv\n",
      "90 yeast-1_vs_7.csv\n",
      "91 yeast-2_vs_4.csv\n",
      "92 yeast.csv\n",
      "93 yeast1.csv\n",
      "94 yeast128.csv\n",
      "95 yeast128_smote.csv\n",
      "96 yeast3.csv\n",
      "97 yeast4.csv\n",
      "98 yeast5.csv\n",
      "99 yeast6.csv\n",
      "100 yeast_ME2.csv\n",
      "101 zoo.csv\n",
      "102 zoo_3.csv\n"
     ]
    }
   ],
   "source": [
    "for i, f in enumerate(CSV_FILES):\n",
    "    print(i ,f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243761ce",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e8bde",
   "metadata": {},
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9acb7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CV         = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "CLASSIFIER = RandomForestClassifier(n_estimators=300,\n",
    "                                    n_jobs=-1,\n",
    "                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5deb1a9",
   "metadata": {},
   "source": [
    "## Sampling Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcbbfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAMPLERS   = {\n",
    "    \"None\"          : None,\n",
    "    \"SMOTE\"         : SMOTE(random_state=42),\n",
    "    \"OverSample\"    : RandomOverSampler(random_state=42),\n",
    "    \"DownSample\"    : RandomUnderSampler(random_state=42),\n",
    "    \"SMOTE_Bagging\" : BalancedBaggingClassifier(random_state=84, sampler = SMOTE(random_state=100, k_neighbors=2)),\n",
    "    \"CNN\"           : CondensedNearestNeighbour(random_state=10, n_jobs=-1),\n",
    "    \"NC\"            : NeighbourhoodCleaningRule(),\n",
    "    \"ICost\"         : OverBoostClassifier(random_state=84),\n",
    "    \"DD_Hybrid\"     : DDHybridSampler(target_ir=1.5, k=5, random_state=42)\n",
    "}\n",
    "\n",
    "SAMPLE_MODEL = [\"ICost\", \"SMOTE_Bagging\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b974e9e4",
   "metadata": {},
   "source": [
    "## Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2f7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "METRICS    = [\"accuracy\", \"macro_precision\", \"macro_recall\", \"macro_f1\",\n",
    "              \"weighted_precision\", \"weighted_recall\", \"weighted_f1\", \"mcc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece335c2",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2506e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(sampler, classifier=CLASSIFIER) -> ImbPipeline:\n",
    "    steps = [\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scale\" , StandardScaler()),          # optional but cheap\n",
    "    ]\n",
    "    if sampler is not None:\n",
    "        steps.append((\"sample\", sampler))\n",
    "    steps.append((\"clf\", classifier))\n",
    "    return ImbPipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bfc0ad",
   "metadata": {},
   "source": [
    "## Scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ae66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_fold(y_true, y_pred) -> dict:\n",
    "    return {\n",
    "        \"accuracy\"          : accuracy_score(y_true, y_pred),\n",
    "        \"macro_precision\"   : precision_score(y_true, y_pred,\n",
    "                                              average=\"macro\", zero_division=0),\n",
    "        \"macro_recall\"      : recall_score(y_true, y_pred,\n",
    "                                           average=\"macro\", zero_division=0),\n",
    "        \"macro_f1\"          : f1_score(y_true, y_pred,\n",
    "                                       average=\"macro\", zero_division=0),\n",
    "        \"weighted_precision\": precision_score(y_true, y_pred,\n",
    "                                              average=\"weighted\", zero_division=0),\n",
    "        \"weighted_recall\"   : recall_score(y_true, y_pred,\n",
    "                                           average=\"weighted\", zero_division=0),\n",
    "        \"weighted_f1\"       : f1_score(y_true, y_pred,\n",
    "                                       average=\"weighted\", zero_division=0),\n",
    "        \"mcc\"               : matthews_corrcoef(y_true, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5897b54",
   "metadata": {},
   "source": [
    "# Master loop – run pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0db76",
   "metadata": {},
   "source": [
    "For all Datasets\n",
    "- Loading Dataset\n",
    "- Label Encoding\n",
    "- Loop for all Sampling Algorithms\n",
    "- Build Pipeline\n",
    "- Train-Test model with StratifiedkFold\n",
    "- Save the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8d01c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalance_ratio(y):\n",
    "    \"\"\"\n",
    "    y : 1-D numpy array of class labels\n",
    "    returns IR (float) = majority_count / minority_count\n",
    "    \"\"\"\n",
    "    counts = np.bincount(y)          # works for integer-encoded labels\n",
    "    return counts.max() / counts.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5fbc83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing BigML_Dataset\t\tTarget Size =  (3333, 21) \t No. of classes =  2\n",
      "\t- Performing Cross-Validation on :  None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'IR'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# mean across folds\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m METRICS:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIR\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[ds_name] = imbalance_ratio(y)\n\u001b[32m     46\u001b[39m     scores[m][samp_name][ds_name] = np.mean(fold_scores[m])\n",
      "\u001b[31mKeyError\u001b[39m: 'IR'"
     ]
    }
   ],
   "source": [
    "scores = {m: {s: {} for s in SAMPLERS} for m in METRICS}   # metric -> sampler -> dataset -> score\n",
    "\n",
    "for dataset_path in CSV_FILES:\n",
    "    ds_name = dataset_path.stem\n",
    "    print(f\"\\nProcessing {ds_name}\" , end=\"\\t\\t\")\n",
    "    \n",
    "    # load + basic cleaning\n",
    "    df = read_data(dataset_path)\n",
    "    df = df.dropna(subset=[df.columns[-1]])\n",
    "    if df.shape[0] < 20:\n",
    "        print(\"Too few samples (<20). Skipping...\")\n",
    "        continue\n",
    "    print(\"Target Size = \", df.shape, \"\\t\", \"No. of classes = \", df.iloc[:, -1].nunique())\n",
    "\n",
    "    X = df.iloc[:, :-1].copy()\n",
    "    y = LabelEncoder().fit_transform(df.iloc[:, -1])\n",
    "\n",
    "    \n",
    "    cat_cols = X.select_dtypes(exclude=np.number).columns\n",
    "    if len(cat_cols):\n",
    "        X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    for samp_name, sampler in SAMPLERS.items():\n",
    "        print(\"\\t- Performing Cross-Validation on : \", samp_name)\n",
    "        if samp_name in SAMPLE_MODEL:\n",
    "            pipe = build_pipeline(None, classifier=sampler)\n",
    "        else:\n",
    "            pipe = build_pipeline(sampler)\n",
    "        fold_scores = {m: [] for m in METRICS}\n",
    "        \n",
    "        for train_idx, val_idx in CV.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            pipe.fit(X_train, y_train)          # ALL steps fitted only on train\n",
    "            y_pred = pipe.predict(X_val)\n",
    "            \n",
    "            for k, v in score_fold(y_val, y_pred).items():\n",
    "                fold_scores[k].append(v)\n",
    "        \n",
    "        # mean across folds\n",
    "        for m in METRICS:\n",
    "            scores[m][\"IR\"][ds_name] = imbalance_ratio(y)\n",
    "            scores[m][samp_name][ds_name] = np.mean(fold_scores[m])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ade385",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f773cb",
   "metadata": {},
   "source": [
    "- Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_metric = {}\n",
    "for metric in METRICS:\n",
    "    df = pd.DataFrame(scores[metric])#.T   # samplers × datasets\n",
    "    # df = df.T                             # datasets × samplers\n",
    "    # df.name = metric\n",
    "    # df_per_metric.append(df)\n",
    "    df_per_metric[metric] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0fb0bb",
   "metadata": {},
   "source": [
    "- Display Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38138e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in df_per_metric:\n",
    "#     print(\"=\"*80)\n",
    "#     print(df.name)\n",
    "#     display(df)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_metric[\"mcc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d0c31",
   "metadata": {},
   "source": [
    "# 7.  Bar-plots: % change vs SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39378c3",
   "metadata": {},
   "source": [
    "- scores of SMOTE is set as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"SMOTE\"\n",
    "\n",
    "# for df in df_per_metric:\n",
    "for name, df in df_per_metric.items():\n",
    "#     metric = df.name\n",
    "    rel = ((df.subtract(df[baseline], axis=0)\n",
    "            .div(df[baseline], axis=0))*100).round(2)\n",
    "    rel = rel.drop(columns=[baseline], errors=\"ignore\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rel.plot(kind=\"bar\", ax=ax, width=0.8)\n",
    "    ax.axhline(0, color=\"black\", lw=0.8)\n",
    "    ax.set_title(f\"{metric} : Change (%) vs {baseline}\")\n",
    "    ax.set_ylabel(\"Change (%)\")\n",
    "    ax.set_xlabel(\"datasets\")\n",
    "    ax.legend(title=\"sampler\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(OUT_DIR/f\"rel_vs_{baseline}_{metric}.png\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3122d768",
   "metadata": {},
   "source": [
    "# 8.  Export CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in df_per_metric:\n",
    "for name, df in df_per_metric.items():\n",
    "    df.to_csv(OUT_DIR/f\"{name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83317279",
   "metadata": {},
   "source": [
    "✅ **Completed**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
