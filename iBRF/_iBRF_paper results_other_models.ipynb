{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b511c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import *\n",
    "from imblearn.over_sampling import *\n",
    "from imblearn.combine import *\n",
    "\n",
    "from imblearn.metrics import sensitivity_score\n",
    "from imblearn.metrics import specificity_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import datasets\n",
    "from scipy import stats\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *\n",
    "from imblearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc= MinMaxScaler()\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aeb79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores={\n",
    "        'gmean': make_scorer(geometric_mean_score),\n",
    "        'roc': make_scorer(roc_auc_score),\n",
    "        'mcc':make_scorer(matthews_corrcoef),\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'sensitivity': make_scorer(sensitivity_score)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60049e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name= [ 'wisconsin', \n",
    "            'vehicle2', \n",
    "            'vehicle1',\n",
    "            'vehicle3', \n",
    "            'new-thyroid1',\n",
    "            'ecoli2',\n",
    "            'glass6', \n",
    "            'yeast',\n",
    "            'yeast3',\n",
    "            'ecoli3',\n",
    "            'yeast-2_vs_4',\n",
    "            'yeast-0-2-5-6_vs_3-7-8-9',\n",
    "            'vowel',\n",
    "            'led7digit-0-2-4-5-6-7-8-9_vs_1',\n",
    "            'glass2',\n",
    "            'ecoli-0-1-4-7_vs_5-6',\n",
    "            'glass4',\n",
    "            'ecoli4',\n",
    "            'page-blocks-1-3_vs_4',\n",
    "            'abalone',\n",
    "            'yeast-1-4-5-8_vs_7',\n",
    "            'yeast4',\n",
    "            'yeast128',\n",
    "            'winequality-red-8_vs_6',\n",
    "            'ecoli_013vs26',\n",
    "            'abalone-17_vs_7-8-9-10',\n",
    "            'winequality-white-3_vs_7',\n",
    "            'winequality-red-8_vs_6-7',\n",
    "            'abalone-19_vs_10-11-12-13',\n",
    "            'winequality-red-3_vs_5',\n",
    "            'abalone_20',\n",
    "            'kddcup-land_vs_satan',\n",
    "            'abalone19'\n",
    "            ]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264c6ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b32c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmean = pd.DataFrame(columns=['dataset'])\n",
    "roc = pd.DataFrame(columns=['dataset'])\n",
    "mcc = pd.DataFrame(columns=['dataset'])\n",
    "accuracy = pd.DataFrame(columns=['dataset'])\n",
    "sensitivity = pd.DataFrame(columns=['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fecfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "count= 1\n",
    "\n",
    "for ii in data_name:\n",
    "    data= pd.read_csv('{}.csv'.format(ii))\n",
    "    x=data.iloc[:,:-1]\n",
    "    y=data.iloc[:,-1]\n",
    "    ir=y.value_counts()[0]/y.value_counts()[1];\n",
    "    ir=round(ir,2)\n",
    "\n",
    "    gmean= pd.concat([gmean, pd.DataFrame({'dataset':ii, 'Imbalance Ratio':ir},index=[0])])\n",
    "    roc= pd.concat([roc, pd.DataFrame({'dataset':ii, 'Imbalance Ratio':ir},index=[0])])\n",
    "    mcc= pd.concat([mcc, pd.DataFrame({'dataset':ii, 'Imbalance Ratio':ir},index=[0])])\n",
    "    accuracy= pd.concat([accuracy, pd.DataFrame({'dataset':ii, 'Imbalance Ratio':ir},index=[0])])\n",
    "    sensitivity = pd.concat([sensitivity, pd.DataFrame({'dataset':ii, 'Imbalance Ratio':ir},index=[0])])\n",
    "\n",
    "    \n",
    "    count= count+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cfad07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Imbalance Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vehicle2</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vehicle1</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vehicle3</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new-thyroid1</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ecoli2</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glass6</td>\n",
       "      <td>6.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast3</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ecoli3</td>\n",
       "      <td>8.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast-2_vs_4</td>\n",
       "      <td>9.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast-0-2-5-6_vs_3-7-8-9</td>\n",
       "      <td>9.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vowel</td>\n",
       "      <td>9.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>led7digit-0-2-4-5-6-7-8-9_vs_1</td>\n",
       "      <td>10.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glass2</td>\n",
       "      <td>11.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ecoli-0-1-4-7_vs_5-6</td>\n",
       "      <td>12.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glass4</td>\n",
       "      <td>15.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ecoli4</td>\n",
       "      <td>15.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>page-blocks-1-3_vs_4</td>\n",
       "      <td>15.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone</td>\n",
       "      <td>16.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast-1-4-5-8_vs_7</td>\n",
       "      <td>22.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>28.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast128</td>\n",
       "      <td>30.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>winequality-red-8_vs_6</td>\n",
       "      <td>35.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ecoli_013vs26</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone-17_vs_7-8-9-10</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>winequality-white-3_vs_7</td>\n",
       "      <td>43.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>winequality-red-8_vs_6-7</td>\n",
       "      <td>46.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone-19_vs_10-11-12-13</td>\n",
       "      <td>51.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>winequality-red-3_vs_5</td>\n",
       "      <td>68.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_20</td>\n",
       "      <td>72.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kddcup-land_vs_satan</td>\n",
       "      <td>79.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone19</td>\n",
       "      <td>129.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dataset  Imbalance Ratio\n",
       "0                       wisconsin             1.86\n",
       "0                        vehicle2             2.88\n",
       "0                        vehicle1             2.90\n",
       "0                        vehicle3             2.99\n",
       "0                    new-thyroid1             5.11\n",
       "0                          ecoli2             5.44\n",
       "0                          glass6             6.34\n",
       "0                           yeast             8.10\n",
       "0                          yeast3             8.10\n",
       "0                          ecoli3             8.57\n",
       "0                    yeast-2_vs_4             9.06\n",
       "0        yeast-0-2-5-6_vs_3-7-8-9             9.13\n",
       "0                           vowel             9.98\n",
       "0  led7digit-0-2-4-5-6-7-8-9_vs_1            10.95\n",
       "0                          glass2            11.53\n",
       "0            ecoli-0-1-4-7_vs_5-6            12.24\n",
       "0                          glass4            15.38\n",
       "0                          ecoli4            15.75\n",
       "0            page-blocks-1-3_vs_4            15.82\n",
       "0                         abalone            16.40\n",
       "0              yeast-1-4-5-8_vs_7            22.07\n",
       "0                          yeast4            28.08\n",
       "0                        yeast128            30.53\n",
       "0          winequality-red-8_vs_6            35.39\n",
       "0                   ecoli_013vs26            39.00\n",
       "0          abalone-17_vs_7-8-9-10            39.29\n",
       "0        winequality-white-3_vs_7            43.95\n",
       "0        winequality-red-8_vs_6-7            46.44\n",
       "0       abalone-19_vs_10-11-12-13            51.29\n",
       "0          winequality-red-3_vs_5            68.00\n",
       "0                      abalone_20            72.65\n",
       "0            kddcup-land_vs_satan            79.45\n",
       "0                       abalone19           129.41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4088329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Index inplace\n",
    "gmean.reset_index(drop=True, inplace=True)\n",
    "roc.reset_index(drop=True, inplace=True)\n",
    "mcc.reset_index(drop=True, inplace=True)\n",
    "accuracy.reset_index(drop=True, inplace=True)\n",
    "sensitivity.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772ce47",
   "metadata": {},
   "source": [
    "### Over-Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93020a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count= 1\n",
    "\n",
    "for ii in data_name:\n",
    "    data= pd.read_csv('{}.csv'.format(ii))\n",
    "    x=data.iloc[:,:-1]\n",
    "    y=data.iloc[:,-1]\n",
    "    x= sc.fit_transform(x)\n",
    "    \n",
    "\n",
    "    Over_Bagging= BalancedBaggingClassifier(random_state=84, sampler = RandomOverSampler(random_state=100))\n",
    "    steps=[('model',Over_Bagging)]\n",
    "    pipeline= Pipeline(steps=steps)\n",
    "    score = cross_validate(pipeline, x,y, cv=StratifiedKFold(5), n_jobs=-1, scoring=scores)\n",
    "    \n",
    "    df1=pd.DataFrame(score)\n",
    "    \n",
    "    x= df1.mean()*100\n",
    "    \n",
    "    gmean.loc[count-1, 'Over-Bagging']= x['test_gmean']\n",
    "    roc.loc[count-1, 'Over-Bagging']= x['test_roc']\n",
    "    mcc.loc[count-1, 'Over-Bagging']= x['test_mcc']\n",
    "    accuracy.loc[count-1, 'Over-Bagging']= x['test_accuracy']\n",
    "    sensitivity.loc[count-1, 'Over-Bagging']= x['test_sensitivity']\n",
    "    \n",
    "    count= count+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24074258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Imbalance Ratio</th>\n",
       "      <th>Over-Bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1.86</td>\n",
       "      <td>90.528052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vehicle2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>91.893833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vehicle1</td>\n",
       "      <td>2.90</td>\n",
       "      <td>38.654234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vehicle3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>38.468441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new-thyroid1</td>\n",
       "      <td>5.11</td>\n",
       "      <td>89.734770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ecoli2</td>\n",
       "      <td>5.44</td>\n",
       "      <td>70.440302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glass6</td>\n",
       "      <td>6.34</td>\n",
       "      <td>86.125782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yeast</td>\n",
       "      <td>8.10</td>\n",
       "      <td>75.069777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yeast3</td>\n",
       "      <td>8.10</td>\n",
       "      <td>74.197739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ecoli3</td>\n",
       "      <td>8.57</td>\n",
       "      <td>48.421703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yeast-2_vs_4</td>\n",
       "      <td>9.06</td>\n",
       "      <td>71.086574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yeast-0-2-5-6_vs_3-7-8-9</td>\n",
       "      <td>9.13</td>\n",
       "      <td>44.804678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vowel</td>\n",
       "      <td>9.98</td>\n",
       "      <td>78.580136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>led7digit-0-2-4-5-6-7-8-9_vs_1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>64.587412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>glass2</td>\n",
       "      <td>11.53</td>\n",
       "      <td>26.220914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ecoli-0-1-4-7_vs_5-6</td>\n",
       "      <td>12.24</td>\n",
       "      <td>67.469267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>glass4</td>\n",
       "      <td>15.38</td>\n",
       "      <td>64.646581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ecoli4</td>\n",
       "      <td>15.75</td>\n",
       "      <td>72.775159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>page-blocks-1-3_vs_4</td>\n",
       "      <td>15.82</td>\n",
       "      <td>73.810606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abalone</td>\n",
       "      <td>16.40</td>\n",
       "      <td>33.004389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>yeast-1-4-5-8_vs_7</td>\n",
       "      <td>22.07</td>\n",
       "      <td>7.651386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>28.08</td>\n",
       "      <td>24.021245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yeast128</td>\n",
       "      <td>30.53</td>\n",
       "      <td>13.004099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>winequality-red-8_vs_6</td>\n",
       "      <td>35.39</td>\n",
       "      <td>4.527559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ecoli_013vs26</td>\n",
       "      <td>39.00</td>\n",
       "      <td>-0.518999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abalone-17_vs_7-8-9-10</td>\n",
       "      <td>39.29</td>\n",
       "      <td>10.816852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>winequality-white-3_vs_7</td>\n",
       "      <td>43.95</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>winequality-red-8_vs_6-7</td>\n",
       "      <td>46.44</td>\n",
       "      <td>9.673974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>abalone-19_vs_10-11-12-13</td>\n",
       "      <td>51.29</td>\n",
       "      <td>-0.152859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>winequality-red-3_vs_5</td>\n",
       "      <td>68.00</td>\n",
       "      <td>-0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>abalone_20</td>\n",
       "      <td>72.65</td>\n",
       "      <td>8.638114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kddcup-land_vs_satan</td>\n",
       "      <td>79.45</td>\n",
       "      <td>94.097733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>abalone19</td>\n",
       "      <td>129.41</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  Imbalance Ratio  Over-Bagging\n",
       "0                        wisconsin             1.86     90.528052\n",
       "1                         vehicle2             2.88     91.893833\n",
       "2                         vehicle1             2.90     38.654234\n",
       "3                         vehicle3             2.99     38.468441\n",
       "4                     new-thyroid1             5.11     89.734770\n",
       "5                           ecoli2             5.44     70.440302\n",
       "6                           glass6             6.34     86.125782\n",
       "7                            yeast             8.10     75.069777\n",
       "8                           yeast3             8.10     74.197739\n",
       "9                           ecoli3             8.57     48.421703\n",
       "10                    yeast-2_vs_4             9.06     71.086574\n",
       "11        yeast-0-2-5-6_vs_3-7-8-9             9.13     44.804678\n",
       "12                           vowel             9.98     78.580136\n",
       "13  led7digit-0-2-4-5-6-7-8-9_vs_1            10.95     64.587412\n",
       "14                          glass2            11.53     26.220914\n",
       "15            ecoli-0-1-4-7_vs_5-6            12.24     67.469267\n",
       "16                          glass4            15.38     64.646581\n",
       "17                          ecoli4            15.75     72.775159\n",
       "18            page-blocks-1-3_vs_4            15.82     73.810606\n",
       "19                         abalone            16.40     33.004389\n",
       "20              yeast-1-4-5-8_vs_7            22.07      7.651386\n",
       "21                          yeast4            28.08     24.021245\n",
       "22                        yeast128            30.53     13.004099\n",
       "23          winequality-red-8_vs_6            35.39      4.527559\n",
       "24                   ecoli_013vs26            39.00     -0.518999\n",
       "25          abalone-17_vs_7-8-9-10            39.29     10.816852\n",
       "26        winequality-white-3_vs_7            43.95      0.000000\n",
       "27        winequality-red-8_vs_6-7            46.44      9.673974\n",
       "28       abalone-19_vs_10-11-12-13            51.29     -0.152859\n",
       "29          winequality-red-3_vs_5            68.00     -0.588235\n",
       "30                      abalone_20            72.65      8.638114\n",
       "31            kddcup-land_vs_satan            79.45     94.097733\n",
       "32                       abalone19           129.41      0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ffd8e",
   "metadata": {},
   "source": [
    "### SMOTE-Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b794f9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 331, in fit\n",
      "    return super().fit(X, y)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 269, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 346, in _fit\n",
      "    return super()._fit(X, y, self.max_samples, sample_weight=None)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 394, in _fit\n",
      "    all_results = Parallel(\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 126, in _parallel_build_estimators\n",
      "    estimator.fit((X[indices])[:, features], y[indices])\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\pipeline.py\", line 268, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\pipeline.py\", line 226, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\pipeline.py\", line 394, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\base.py\", line 83, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 324, in _fit_resample\n",
      "    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 4\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "3 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 331, in fit\n",
      "    return super().fit(X, y)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 269, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 346, in _fit\n",
      "    return super()._fit(X, y, self.max_samples, sample_weight=None)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 394, in _fit\n",
      "    all_results = Parallel(\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 126, in _parallel_build_estimators\n",
      "    estimator.fit((X[indices])[:, features], y[indices])\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\pipeline.py\", line 268, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\pipeline.py\", line 226, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\pipeline.py\", line 394, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\base.py\", line 83, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 324, in _fit_resample\n",
      "    nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]\n",
      "  File \"D:\\apps\\anaconda\\anaconda\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 727, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 4\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "count= 1\n",
    "\n",
    "for ii in data_name:\n",
    "    data= pd.read_csv('{}.csv'.format(ii))\n",
    "    x=data.iloc[:,:-1]\n",
    "    y=data.iloc[:,-1]\n",
    "    x= sc.fit_transform(x)\n",
    "    \n",
    "\n",
    "    SMOTE_Bagging= BalancedBaggingClassifier(random_state=84, sampler = SMOTE(random_state=100, k_neighbors=3))\n",
    "    steps=[('model', SMOTE_Bagging)]\n",
    "    pipeline= Pipeline(steps=steps)\n",
    "    score = cross_validate(pipeline, x,y, cv=StratifiedKFold(5), n_jobs=-1, scoring=scores)\n",
    "    \n",
    "    df1=pd.DataFrame(score)\n",
    "    \n",
    "    x= df1.mean()*100\n",
    "    \n",
    "    gmean.loc[count-1, 'SMOTE-Bagging']= x['test_gmean']\n",
    "    roc.loc[count-1, 'SMOTE-Bagging']= x['test_roc']\n",
    "    mcc.loc[count-1, 'SMOTE-Bagging']= x['test_mcc']\n",
    "    accuracy.loc[count-1, 'SMOTE-Bagging']= x['test_accuracy']\n",
    "    sensitivity.loc[count-1, 'SMOTE-Bagging']= x['test_sensitivity']\n",
    "    \n",
    "    count= count+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5538b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           dataset  Imbalance Ratio  Over-Bagging  \\\n",
      "0                        wisconsin             1.86     90.528052   \n",
      "1                         vehicle2             2.88     91.893833   \n",
      "2                         vehicle1             2.90     38.654234   \n",
      "3                         vehicle3             2.99     38.468441   \n",
      "4                     new-thyroid1             5.11     89.734770   \n",
      "5                           ecoli2             5.44     70.440302   \n",
      "6                           glass6             6.34     86.125782   \n",
      "7                            yeast             8.10     75.069777   \n",
      "8                           yeast3             8.10     74.197739   \n",
      "9                           ecoli3             8.57     48.421703   \n",
      "10                    yeast-2_vs_4             9.06     71.086574   \n",
      "11        yeast-0-2-5-6_vs_3-7-8-9             9.13     44.804678   \n",
      "12                           vowel             9.98     78.580136   \n",
      "13  led7digit-0-2-4-5-6-7-8-9_vs_1            10.95     64.587412   \n",
      "14                          glass2            11.53     26.220914   \n",
      "15            ecoli-0-1-4-7_vs_5-6            12.24     67.469267   \n",
      "16                          glass4            15.38     64.646581   \n",
      "17                          ecoli4            15.75     72.775159   \n",
      "18            page-blocks-1-3_vs_4            15.82     73.810606   \n",
      "19                         abalone            16.40     33.004389   \n",
      "20              yeast-1-4-5-8_vs_7            22.07      7.651386   \n",
      "21                          yeast4            28.08     24.021245   \n",
      "22                        yeast128            30.53     13.004099   \n",
      "23          winequality-red-8_vs_6            35.39      4.527559   \n",
      "24                   ecoli_013vs26            39.00     -0.518999   \n",
      "25          abalone-17_vs_7-8-9-10            39.29     10.816852   \n",
      "26        winequality-white-3_vs_7            43.95      0.000000   \n",
      "27        winequality-red-8_vs_6-7            46.44      9.673974   \n",
      "28       abalone-19_vs_10-11-12-13            51.29     -0.152859   \n",
      "29          winequality-red-3_vs_5            68.00     -0.588235   \n",
      "30                      abalone_20            72.65      8.638114   \n",
      "31            kddcup-land_vs_satan            79.45     94.097733   \n",
      "32                       abalone19           129.41      0.000000   \n",
      "\n",
      "    SMOTE-Bagging  \n",
      "0       89.203349  \n",
      "1       92.270894  \n",
      "2       41.195754  \n",
      "3       37.380118  \n",
      "4       89.790218  \n",
      "5       76.941879  \n",
      "6       86.125782  \n",
      "7       75.088067  \n",
      "8       72.480884  \n",
      "9       61.540028  \n",
      "10      74.842381  \n",
      "11      42.042953  \n",
      "12      79.128950  \n",
      "13      67.359763  \n",
      "14      19.666700  \n",
      "15      69.524582  \n",
      "16      53.219728  \n",
      "17      70.944368  \n",
      "18      73.810606  \n",
      "19      29.620776  \n",
      "20       6.283761  \n",
      "21      37.898498  \n",
      "22      15.845927  \n",
      "23       8.286914  \n",
      "24      33.333333  \n",
      "25      18.225739  \n",
      "26      -0.225360  \n",
      "27       6.447115  \n",
      "28       1.757674  \n",
      "29       0.000000  \n",
      "30      20.789613  \n",
      "31      94.097733  \n",
      "32      -0.410146  \n"
     ]
    }
   ],
   "source": [
    "print(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d6eb0",
   "metadata": {},
   "source": [
    "### NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5756924",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier(random_state=10)\n",
    "count= 1\n",
    "\n",
    "for ii in data_name:\n",
    "    data= pd.read_csv('{}.csv'.format(ii))\n",
    "    x=data.iloc[:,:-1]\n",
    "    y=data.iloc[:,-1]\n",
    "    x= sc.fit_transform(x)\n",
    "    \n",
    "\n",
    "    nc= NeighbourhoodCleaningRule()\n",
    "    steps=[('sampling', nc),('model',rf)]\n",
    "    pipeline= Pipeline(steps=steps)\n",
    "    score = cross_validate(pipeline, x,y, cv=StratifiedKFold(5), n_jobs=-1, scoring=scores)\n",
    "    \n",
    "    df1=pd.DataFrame(score)\n",
    "    \n",
    "    x= df1.mean()*100\n",
    "    \n",
    "    gmean.loc[count-1, 'NC']= x['test_gmean']\n",
    "    roc.loc[count-1, 'NC']= x['test_roc']\n",
    "    mcc.loc[count-1, 'NC']= x['test_mcc']\n",
    "    accuracy.loc[count-1, 'NC']= x['test_accuracy']\n",
    "    sensitivity.loc[count-1, 'NC']= x['test_sensitivity']\n",
    "    \n",
    "    count= count+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9263db08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Imbalance Ratio</th>\n",
       "      <th>Over-Bagging</th>\n",
       "      <th>SMOTE-Bagging</th>\n",
       "      <th>NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1.86</td>\n",
       "      <td>94.984963</td>\n",
       "      <td>94.252037</td>\n",
       "      <td>97.173136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vehicle2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>94.944738</td>\n",
       "      <td>96.061567</td>\n",
       "      <td>98.050955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vehicle1</td>\n",
       "      <td>2.90</td>\n",
       "      <td>67.588285</td>\n",
       "      <td>69.596444</td>\n",
       "      <td>79.091373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vehicle3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>66.728461</td>\n",
       "      <td>67.437922</td>\n",
       "      <td>76.111329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new-thyroid1</td>\n",
       "      <td>5.11</td>\n",
       "      <td>93.722222</td>\n",
       "      <td>93.722222</td>\n",
       "      <td>95.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ecoli2</td>\n",
       "      <td>5.44</td>\n",
       "      <td>84.158863</td>\n",
       "      <td>88.249658</td>\n",
       "      <td>88.334188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glass6</td>\n",
       "      <td>6.34</td>\n",
       "      <td>92.515015</td>\n",
       "      <td>92.515015</td>\n",
       "      <td>93.618619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yeast</td>\n",
       "      <td>8.10</td>\n",
       "      <td>86.307962</td>\n",
       "      <td>87.368568</td>\n",
       "      <td>89.366674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yeast3</td>\n",
       "      <td>8.10</td>\n",
       "      <td>85.700758</td>\n",
       "      <td>85.984848</td>\n",
       "      <td>89.346591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ecoli3</td>\n",
       "      <td>8.57</td>\n",
       "      <td>72.119048</td>\n",
       "      <td>81.952381</td>\n",
       "      <td>81.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yeast-2_vs_4</td>\n",
       "      <td>9.06</td>\n",
       "      <td>83.374602</td>\n",
       "      <td>88.651643</td>\n",
       "      <td>88.883314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yeast-0-2-5-6_vs_3-7-8-9</td>\n",
       "      <td>9.13</td>\n",
       "      <td>69.806856</td>\n",
       "      <td>68.780072</td>\n",
       "      <td>76.971826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vowel</td>\n",
       "      <td>9.98</td>\n",
       "      <td>88.055556</td>\n",
       "      <td>89.055245</td>\n",
       "      <td>77.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>led7digit-0-2-4-5-6-7-8-9_vs_1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>82.810847</td>\n",
       "      <td>84.733245</td>\n",
       "      <td>84.486332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>glass2</td>\n",
       "      <td>11.53</td>\n",
       "      <td>57.820513</td>\n",
       "      <td>56.538462</td>\n",
       "      <td>53.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ecoli-0-1-4-7_vs_5-6</td>\n",
       "      <td>12.24</td>\n",
       "      <td>80.524590</td>\n",
       "      <td>82.393443</td>\n",
       "      <td>79.245902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>glass4</td>\n",
       "      <td>15.38</td>\n",
       "      <td>76.583333</td>\n",
       "      <td>75.583333</td>\n",
       "      <td>85.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ecoli4</td>\n",
       "      <td>15.75</td>\n",
       "      <td>84.047619</td>\n",
       "      <td>83.571429</td>\n",
       "      <td>81.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>page-blocks-1-3_vs_4</td>\n",
       "      <td>15.82</td>\n",
       "      <td>85.537879</td>\n",
       "      <td>85.537879</td>\n",
       "      <td>86.984848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abalone</td>\n",
       "      <td>16.40</td>\n",
       "      <td>58.043478</td>\n",
       "      <td>62.641754</td>\n",
       "      <td>59.286911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>yeast-1-4-5-8_vs_7</td>\n",
       "      <td>22.07</td>\n",
       "      <td>51.590909</td>\n",
       "      <td>51.062315</td>\n",
       "      <td>49.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>28.08</td>\n",
       "      <td>56.538949</td>\n",
       "      <td>64.952145</td>\n",
       "      <td>62.377988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yeast128</td>\n",
       "      <td>30.53</td>\n",
       "      <td>54.726776</td>\n",
       "      <td>56.229508</td>\n",
       "      <td>52.950820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>winequality-red-8_vs_6</td>\n",
       "      <td>35.39</td>\n",
       "      <td>52.263780</td>\n",
       "      <td>54.685655</td>\n",
       "      <td>52.186270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ecoli_013vs26</td>\n",
       "      <td>39.00</td>\n",
       "      <td>49.814815</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>69.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abalone-17_vs_7-8-9-10</td>\n",
       "      <td>39.29</td>\n",
       "      <td>52.400030</td>\n",
       "      <td>56.805063</td>\n",
       "      <td>55.643216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>winequality-white-3_vs_7</td>\n",
       "      <td>43.95</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.943182</td>\n",
       "      <td>54.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>winequality-red-8_vs_6-7</td>\n",
       "      <td>46.44</td>\n",
       "      <td>52.440120</td>\n",
       "      <td>52.260479</td>\n",
       "      <td>54.820359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>abalone-19_vs_10-11-12-13</td>\n",
       "      <td>51.29</td>\n",
       "      <td>49.968553</td>\n",
       "      <td>51.257862</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>winequality-red-3_vs_5</td>\n",
       "      <td>68.00</td>\n",
       "      <td>49.705882</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.852941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>abalone_20</td>\n",
       "      <td>72.65</td>\n",
       "      <td>51.893899</td>\n",
       "      <td>57.295875</td>\n",
       "      <td>53.893899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kddcup-land_vs_satan</td>\n",
       "      <td>79.45</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>97.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>abalone19</td>\n",
       "      <td>129.41</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.843083</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  Imbalance Ratio  Over-Bagging  \\\n",
       "0                        wisconsin             1.86     94.984963   \n",
       "1                         vehicle2             2.88     94.944738   \n",
       "2                         vehicle1             2.90     67.588285   \n",
       "3                         vehicle3             2.99     66.728461   \n",
       "4                     new-thyroid1             5.11     93.722222   \n",
       "5                           ecoli2             5.44     84.158863   \n",
       "6                           glass6             6.34     92.515015   \n",
       "7                            yeast             8.10     86.307962   \n",
       "8                           yeast3             8.10     85.700758   \n",
       "9                           ecoli3             8.57     72.119048   \n",
       "10                    yeast-2_vs_4             9.06     83.374602   \n",
       "11        yeast-0-2-5-6_vs_3-7-8-9             9.13     69.806856   \n",
       "12                           vowel             9.98     88.055556   \n",
       "13  led7digit-0-2-4-5-6-7-8-9_vs_1            10.95     82.810847   \n",
       "14                          glass2            11.53     57.820513   \n",
       "15            ecoli-0-1-4-7_vs_5-6            12.24     80.524590   \n",
       "16                          glass4            15.38     76.583333   \n",
       "17                          ecoli4            15.75     84.047619   \n",
       "18            page-blocks-1-3_vs_4            15.82     85.537879   \n",
       "19                         abalone            16.40     58.043478   \n",
       "20              yeast-1-4-5-8_vs_7            22.07     51.590909   \n",
       "21                          yeast4            28.08     56.538949   \n",
       "22                        yeast128            30.53     54.726776   \n",
       "23          winequality-red-8_vs_6            35.39     52.263780   \n",
       "24                   ecoli_013vs26            39.00     49.814815   \n",
       "25          abalone-17_vs_7-8-9-10            39.29     52.400030   \n",
       "26        winequality-white-3_vs_7            43.95     50.000000   \n",
       "27        winequality-red-8_vs_6-7            46.44     52.440120   \n",
       "28       abalone-19_vs_10-11-12-13            51.29     49.968553   \n",
       "29          winequality-red-3_vs_5            68.00     49.705882   \n",
       "30                      abalone_20            72.65     51.893899   \n",
       "31            kddcup-land_vs_satan            79.45     95.000000   \n",
       "32                       abalone19           129.41     50.000000   \n",
       "\n",
       "    SMOTE-Bagging         NC  \n",
       "0       94.252037  97.173136  \n",
       "1       96.061567  98.050955  \n",
       "2       69.596444  79.091373  \n",
       "3       67.437922  76.111329  \n",
       "4       93.722222  95.714286  \n",
       "5       88.249658  88.334188  \n",
       "6       92.515015  93.618619  \n",
       "7       87.368568  89.366674  \n",
       "8       85.984848  89.346591  \n",
       "9       81.952381  81.285714  \n",
       "10      88.651643  88.883314  \n",
       "11      68.780072  76.971826  \n",
       "12      89.055245  77.888889  \n",
       "13      84.733245  84.486332  \n",
       "14      56.538462  53.980769  \n",
       "15      82.393443  79.245902  \n",
       "16      75.583333  85.833333  \n",
       "17      83.571429  81.190476  \n",
       "18      85.537879  86.984848  \n",
       "19      62.641754  59.286911  \n",
       "20      51.062315  49.848485  \n",
       "21      64.952145  62.377988  \n",
       "22      56.229508  52.950820  \n",
       "23      54.685655  52.186270  \n",
       "24      66.666667  69.814815  \n",
       "25      56.805063  55.643216  \n",
       "26      49.943182  54.942857  \n",
       "27      52.260479  54.820359  \n",
       "28      51.257862  50.000000  \n",
       "29      50.000000  49.852941  \n",
       "30      57.295875  53.893899  \n",
       "31      95.000000  97.500000  \n",
       "32      49.843083  50.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a633f61a",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bacd74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier(random_state=10)\n",
    "count= 1\n",
    "\n",
    "for ii in data_name:\n",
    "    data= pd.read_csv('{}.csv'.format(ii))\n",
    "    x=data.iloc[:,:-1]\n",
    "    y=data.iloc[:,-1]\n",
    "    x= sc.fit_transform(x)\n",
    "    \n",
    "\n",
    "    cnn= CondensedNearestNeighbour(random_state=10, n_jobs=-1)\n",
    "    steps=[('sampling', cnn),('model',rf)]\n",
    "    pipeline= Pipeline(steps=steps)\n",
    "    score = cross_validate(pipeline, x,y, cv=StratifiedKFold(5), n_jobs=-1, scoring=scores)\n",
    "    \n",
    "    df1=pd.DataFrame(score)\n",
    "    \n",
    "    x= df1.mean()*100\n",
    "    \n",
    "    gmean.loc[count-1, 'CNN']= x['test_gmean']\n",
    "    roc.loc[count-1, 'CNN']= x['test_roc']\n",
    "    mcc.loc[count-1, 'CNN']= x['test_mcc']\n",
    "    accuracy.loc[count-1, 'CNN']= x['test_accuracy']\n",
    "    sensitivity.loc[count-1, 'CNN']= x['test_sensitivity']\n",
    "    \n",
    "    count= count+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ce7e2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Imbalance Ratio</th>\n",
       "      <th>Over-Bagging</th>\n",
       "      <th>SMOTE-Bagging</th>\n",
       "      <th>NC</th>\n",
       "      <th>CNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1.86</td>\n",
       "      <td>90.528052</td>\n",
       "      <td>89.203349</td>\n",
       "      <td>93.737384</td>\n",
       "      <td>92.174009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vehicle2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>91.893833</td>\n",
       "      <td>92.270894</td>\n",
       "      <td>95.408171</td>\n",
       "      <td>94.623106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vehicle1</td>\n",
       "      <td>2.90</td>\n",
       "      <td>38.654234</td>\n",
       "      <td>41.195754</td>\n",
       "      <td>52.216259</td>\n",
       "      <td>49.618697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vehicle3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>38.468441</td>\n",
       "      <td>37.380118</td>\n",
       "      <td>46.714760</td>\n",
       "      <td>42.927883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new-thyroid1</td>\n",
       "      <td>5.11</td>\n",
       "      <td>89.734770</td>\n",
       "      <td>89.790218</td>\n",
       "      <td>94.716721</td>\n",
       "      <td>88.927348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ecoli2</td>\n",
       "      <td>5.44</td>\n",
       "      <td>70.440302</td>\n",
       "      <td>76.941879</td>\n",
       "      <td>77.760230</td>\n",
       "      <td>74.532264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glass6</td>\n",
       "      <td>6.34</td>\n",
       "      <td>86.125782</td>\n",
       "      <td>86.125782</td>\n",
       "      <td>86.536234</td>\n",
       "      <td>82.338630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yeast</td>\n",
       "      <td>8.10</td>\n",
       "      <td>75.069777</td>\n",
       "      <td>75.088067</td>\n",
       "      <td>77.426893</td>\n",
       "      <td>76.647412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yeast3</td>\n",
       "      <td>8.10</td>\n",
       "      <td>74.197739</td>\n",
       "      <td>72.480884</td>\n",
       "      <td>77.376389</td>\n",
       "      <td>78.142842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ecoli3</td>\n",
       "      <td>8.57</td>\n",
       "      <td>48.421703</td>\n",
       "      <td>61.540028</td>\n",
       "      <td>58.144347</td>\n",
       "      <td>54.196504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yeast-2_vs_4</td>\n",
       "      <td>9.06</td>\n",
       "      <td>71.086574</td>\n",
       "      <td>74.842381</td>\n",
       "      <td>77.341152</td>\n",
       "      <td>77.163196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yeast-0-2-5-6_vs_3-7-8-9</td>\n",
       "      <td>9.13</td>\n",
       "      <td>44.804678</td>\n",
       "      <td>42.042953</td>\n",
       "      <td>56.529840</td>\n",
       "      <td>52.302625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vowel</td>\n",
       "      <td>9.98</td>\n",
       "      <td>78.580136</td>\n",
       "      <td>79.128950</td>\n",
       "      <td>68.662774</td>\n",
       "      <td>75.845021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>led7digit-0-2-4-5-6-7-8-9_vs_1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>64.587412</td>\n",
       "      <td>67.359763</td>\n",
       "      <td>67.616571</td>\n",
       "      <td>69.603815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>glass2</td>\n",
       "      <td>11.53</td>\n",
       "      <td>26.220914</td>\n",
       "      <td>19.666700</td>\n",
       "      <td>12.456257</td>\n",
       "      <td>16.011045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ecoli-0-1-4-7_vs_5-6</td>\n",
       "      <td>12.24</td>\n",
       "      <td>67.469267</td>\n",
       "      <td>69.524582</td>\n",
       "      <td>64.232813</td>\n",
       "      <td>67.998262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>glass4</td>\n",
       "      <td>15.38</td>\n",
       "      <td>64.646581</td>\n",
       "      <td>53.219728</td>\n",
       "      <td>65.487155</td>\n",
       "      <td>46.772860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ecoli4</td>\n",
       "      <td>15.75</td>\n",
       "      <td>72.775159</td>\n",
       "      <td>70.944368</td>\n",
       "      <td>66.825225</td>\n",
       "      <td>68.871590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>page-blocks-1-3_vs_4</td>\n",
       "      <td>15.82</td>\n",
       "      <td>73.810606</td>\n",
       "      <td>73.810606</td>\n",
       "      <td>78.254182</td>\n",
       "      <td>87.461293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abalone</td>\n",
       "      <td>16.40</td>\n",
       "      <td>33.004389</td>\n",
       "      <td>29.620776</td>\n",
       "      <td>30.738487</td>\n",
       "      <td>28.244082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>yeast-1-4-5-8_vs_7</td>\n",
       "      <td>22.07</td>\n",
       "      <td>7.651386</td>\n",
       "      <td>6.283761</td>\n",
       "      <td>-0.517088</td>\n",
       "      <td>9.730129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>28.08</td>\n",
       "      <td>24.021245</td>\n",
       "      <td>37.898498</td>\n",
       "      <td>38.042700</td>\n",
       "      <td>33.986855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yeast128</td>\n",
       "      <td>30.53</td>\n",
       "      <td>13.004099</td>\n",
       "      <td>15.845927</td>\n",
       "      <td>10.314303</td>\n",
       "      <td>17.453955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>winequality-red-8_vs_6</td>\n",
       "      <td>35.39</td>\n",
       "      <td>4.527559</td>\n",
       "      <td>8.286914</td>\n",
       "      <td>9.060740</td>\n",
       "      <td>9.647660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ecoli_013vs26</td>\n",
       "      <td>39.00</td>\n",
       "      <td>-0.518999</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>36.178022</td>\n",
       "      <td>26.751248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abalone-17_vs_7-8-9-10</td>\n",
       "      <td>39.29</td>\n",
       "      <td>10.816852</td>\n",
       "      <td>18.225739</td>\n",
       "      <td>19.227157</td>\n",
       "      <td>25.112818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>winequality-white-3_vs_7</td>\n",
       "      <td>43.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.225360</td>\n",
       "      <td>16.786143</td>\n",
       "      <td>45.919104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>winequality-red-8_vs_6-7</td>\n",
       "      <td>46.44</td>\n",
       "      <td>9.673974</td>\n",
       "      <td>6.447115</td>\n",
       "      <td>19.463462</td>\n",
       "      <td>21.122090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>abalone-19_vs_10-11-12-13</td>\n",
       "      <td>51.29</td>\n",
       "      <td>-0.152859</td>\n",
       "      <td>1.757674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.593869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>winequality-red-3_vs_5</td>\n",
       "      <td>68.00</td>\n",
       "      <td>-0.588235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>-0.889294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>abalone_20</td>\n",
       "      <td>72.65</td>\n",
       "      <td>8.638114</td>\n",
       "      <td>20.789613</td>\n",
       "      <td>12.340006</td>\n",
       "      <td>17.989574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kddcup-land_vs_satan</td>\n",
       "      <td>79.45</td>\n",
       "      <td>94.097733</td>\n",
       "      <td>94.097733</td>\n",
       "      <td>97.293253</td>\n",
       "      <td>96.278499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>abalone19</td>\n",
       "      <td>129.41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.410146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.058989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  Imbalance Ratio  Over-Bagging  \\\n",
       "0                        wisconsin             1.86     90.528052   \n",
       "1                         vehicle2             2.88     91.893833   \n",
       "2                         vehicle1             2.90     38.654234   \n",
       "3                         vehicle3             2.99     38.468441   \n",
       "4                     new-thyroid1             5.11     89.734770   \n",
       "5                           ecoli2             5.44     70.440302   \n",
       "6                           glass6             6.34     86.125782   \n",
       "7                            yeast             8.10     75.069777   \n",
       "8                           yeast3             8.10     74.197739   \n",
       "9                           ecoli3             8.57     48.421703   \n",
       "10                    yeast-2_vs_4             9.06     71.086574   \n",
       "11        yeast-0-2-5-6_vs_3-7-8-9             9.13     44.804678   \n",
       "12                           vowel             9.98     78.580136   \n",
       "13  led7digit-0-2-4-5-6-7-8-9_vs_1            10.95     64.587412   \n",
       "14                          glass2            11.53     26.220914   \n",
       "15            ecoli-0-1-4-7_vs_5-6            12.24     67.469267   \n",
       "16                          glass4            15.38     64.646581   \n",
       "17                          ecoli4            15.75     72.775159   \n",
       "18            page-blocks-1-3_vs_4            15.82     73.810606   \n",
       "19                         abalone            16.40     33.004389   \n",
       "20              yeast-1-4-5-8_vs_7            22.07      7.651386   \n",
       "21                          yeast4            28.08     24.021245   \n",
       "22                        yeast128            30.53     13.004099   \n",
       "23          winequality-red-8_vs_6            35.39      4.527559   \n",
       "24                   ecoli_013vs26            39.00     -0.518999   \n",
       "25          abalone-17_vs_7-8-9-10            39.29     10.816852   \n",
       "26        winequality-white-3_vs_7            43.95      0.000000   \n",
       "27        winequality-red-8_vs_6-7            46.44      9.673974   \n",
       "28       abalone-19_vs_10-11-12-13            51.29     -0.152859   \n",
       "29          winequality-red-3_vs_5            68.00     -0.588235   \n",
       "30                      abalone_20            72.65      8.638114   \n",
       "31            kddcup-land_vs_satan            79.45     94.097733   \n",
       "32                       abalone19           129.41      0.000000   \n",
       "\n",
       "    SMOTE-Bagging         NC        CNN  \n",
       "0       89.203349  93.737384  92.174009  \n",
       "1       92.270894  95.408171  94.623106  \n",
       "2       41.195754  52.216259  49.618697  \n",
       "3       37.380118  46.714760  42.927883  \n",
       "4       89.790218  94.716721  88.927348  \n",
       "5       76.941879  77.760230  74.532264  \n",
       "6       86.125782  86.536234  82.338630  \n",
       "7       75.088067  77.426893  76.647412  \n",
       "8       72.480884  77.376389  78.142842  \n",
       "9       61.540028  58.144347  54.196504  \n",
       "10      74.842381  77.341152  77.163196  \n",
       "11      42.042953  56.529840  52.302625  \n",
       "12      79.128950  68.662774  75.845021  \n",
       "13      67.359763  67.616571  69.603815  \n",
       "14      19.666700  12.456257  16.011045  \n",
       "15      69.524582  64.232813  67.998262  \n",
       "16      53.219728  65.487155  46.772860  \n",
       "17      70.944368  66.825225  68.871590  \n",
       "18      73.810606  78.254182  87.461293  \n",
       "19      29.620776  30.738487  28.244082  \n",
       "20       6.283761  -0.517088   9.730129  \n",
       "21      37.898498  38.042700  33.986855  \n",
       "22      15.845927  10.314303  17.453955  \n",
       "23       8.286914   9.060740   9.647660  \n",
       "24      33.333333  36.178022  26.751248  \n",
       "25      18.225739  19.227157  25.112818  \n",
       "26      -0.225360  16.786143  45.919104  \n",
       "27       6.447115  19.463462  21.122090  \n",
       "28       1.757674   0.000000  -0.593869  \n",
       "29       0.000000  -0.294118  -0.889294  \n",
       "30      20.789613  12.340006  17.989574  \n",
       "31      94.097733  97.293253  96.278499  \n",
       "32      -0.410146   0.000000  -0.058989  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5990b",
   "metadata": {},
   "source": [
    "### over boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45318cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble._base import _set_random_states\n",
    "from sklearn.utils import _safe_indexing\n",
    "\n",
    "from imblearn.under_sampling.base import BaseUnderSampler\n",
    "from imblearn.over_sampling.base import BaseOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.utils import Substitution, check_target_type\n",
    "from imblearn.utils._docstring import _random_state_docstring\n",
    "from imblearn.utils._validation import _deprecate_positional_args\n",
    "\n",
    "\n",
    "@Substitution(\n",
    "    sampling_strategy=BaseOverSampler._sampling_strategy_docstring,\n",
    "    random_state=_random_state_docstring,\n",
    ")\n",
    "class OverBoostClassifier(AdaBoostClassifier):\n",
    "    \"\"\"Random under-sampling integrated in the learning of AdaBoost.\n",
    "    During learning, the problem of class balancing is alleviated by random\n",
    "    under-sampling the sample at each iteration of the boosting algorithm.\n",
    "    Read more in the :ref:`User Guide <boosting>`.\n",
    "    .. versionadded:: 0.4\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator : estimator object, default=None\n",
    "        The base estimator from which the boosted ensemble is built.\n",
    "        Support for sample weighting is required, as well as proper\n",
    "        ``classes_`` and ``n_classes_`` attributes. If ``None``, then\n",
    "        the base estimator is ``DecisionTreeClassifier(max_depth=1)``.\n",
    "    n_estimators : int, default=50\n",
    "        The maximum number of estimators at which boosting is terminated.\n",
    "        In case of perfect fit, the learning procedure is stopped early.\n",
    "    learning_rate : float, default=1.0\n",
    "        Learning rate shrinks the contribution of each classifier by\n",
    "        ``learning_rate``. There is a trade-off between ``learning_rate`` and\n",
    "        ``n_estimators``.\n",
    "    algorithm : {{'SAMME', 'SAMME.R'}}, default='SAMME.R'\n",
    "        If 'SAMME.R' then use the SAMME.R real boosting algorithm.\n",
    "        ``base_estimator`` must support calculation of class probabilities.\n",
    "        If 'SAMME' then use the SAMME discrete boosting algorithm.\n",
    "        The SAMME.R algorithm typically converges faster than SAMME,\n",
    "        achieving a lower test error with fewer boosting iterations.\n",
    "    {sampling_strategy}\n",
    "    replacement : bool, default=False\n",
    "        Whether or not to sample randomly with replacement or not.\n",
    "    {random_state}\n",
    "    Attributes\n",
    "    ----------\n",
    "    base_estimator_ : estimator\n",
    "        The base estimator from which the ensemble is grown.\n",
    "    estimators_ : list of classifiers\n",
    "        The collection of fitted sub-estimators.\n",
    "    base_sampler_ : :class:`~imblearn.under_sampling.RandomUnderSampler`\n",
    "        The base sampler used to generate the subsequent samplers.\n",
    "    samplers_ : list of :class:`~imblearn.under_sampling.RandomUnderSampler`\n",
    "        The collection of fitted samplers.\n",
    "    pipelines_ : list of Pipeline\n",
    "        The collection of fitted pipelines (samplers + trees).\n",
    "    classes_ : ndarray of shape (n_classes,)\n",
    "        The classes labels.\n",
    "    n_classes_ : int\n",
    "        The number of classes.\n",
    "    estimator_weights_ : ndarray of shape (n_estimator,)\n",
    "        Weights for each estimator in the boosted ensemble.\n",
    "    estimator_errors_ : ndarray of shape (n_estimator,)\n",
    "        Classification error for each estimator in the boosted\n",
    "        ensemble.\n",
    "    feature_importances_ : ndarray of shape (n_features,)\n",
    "        The feature importances if supported by the ``base_estimator``.\n",
    "    n_features_in_ : int\n",
    "        Number of features in the input dataset.\n",
    "        .. versionadded:: 0.9\n",
    "    See Also\n",
    "    --------\n",
    "    BalancedBaggingClassifier : Bagging classifier for which each base\n",
    "        estimator is trained on a balanced bootstrap.\n",
    "    BalancedRandomForestClassifier : Random forest applying random-under\n",
    "        sampling to balance the different bootstraps.\n",
    "    EasyEnsembleClassifier : Ensemble of AdaBoost classifier trained on\n",
    "        balanced bootstraps.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Seiffert, C., Khoshgoftaar, T. M., Van Hulse, J., & Napolitano, A.\n",
    "       \"RUSBoost: A hybrid approach to alleviating class imbalance.\" IEEE\n",
    "       Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans\n",
    "       40.1 (2010): 185-197.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from imblearn.ensemble import RUSBoostClassifier\n",
    "    >>> from sklearn.datasets import make_classification\n",
    "    >>>\n",
    "    >>> X, y = make_classification(n_samples=1000, n_classes=3,\n",
    "    ...                            n_informative=4, weights=[0.2, 0.3, 0.5],\n",
    "    ...                            random_state=0)\n",
    "    >>> clf = RUSBoostClassifier(random_state=0)\n",
    "    >>> clf.fit(X, y)  # doctest: +ELLIPSIS\n",
    "    RUSBoostClassifier(...)\n",
    "    >>> clf.predict(X)  # doctest: +ELLIPSIS\n",
    "    array([...])\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_estimator=None,\n",
    "        *,\n",
    "        n_estimators=50,\n",
    "        learning_rate=1.0,\n",
    "        algorithm=\"SAMME.R\",\n",
    "        sampling_strategy=\"auto\",\n",
    "        replacement=False,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            base_estimator=base_estimator,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            algorithm=algorithm,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.replacement = replacement\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        \"\"\"Build a boosted classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
    "            DOK, or LIL. DOK and LIL are converted to CSR.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target values (class labels).\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Sample weights. If None, the sample weights are initialized to\n",
    "            ``1 / n_samples``.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        check_target_type(y)\n",
    "        self.samplers_ = []\n",
    "        self.pipelines_ = []\n",
    "        super().fit(X, y, sample_weight)\n",
    "        return self\n",
    "\n",
    "    def _validate_estimator(self):\n",
    "        \"\"\"Check the estimator and the n_estimator attribute, set the\n",
    "        `base_estimator_` attribute.\"\"\"\n",
    "        super()._validate_estimator()\n",
    "\n",
    "        self.base_sampler_ = RandomOverSampler(\n",
    "            sampling_strategy=self.sampling_strategy,\n",
    "            \n",
    "        )\n",
    "\n",
    "    def _make_sampler_estimator(self, append=True, random_state=None):\n",
    "        \"\"\"Make and configure a copy of the `base_estimator_` attribute.\n",
    "        Warning: This method should be used to properly instantiate new\n",
    "        sub-estimators.\n",
    "        \"\"\"\n",
    "        estimator = clone(self.base_estimator_)\n",
    "        estimator.set_params(**{p: getattr(self, p) for p in self.estimator_params})\n",
    "        sampler = clone(self.base_sampler_)\n",
    "\n",
    "        if random_state is not None:\n",
    "            _set_random_states(estimator, random_state)\n",
    "            _set_random_states(sampler, random_state)\n",
    "\n",
    "        if append:\n",
    "            self.estimators_.append(estimator)\n",
    "            self.samplers_.append(sampler)\n",
    "            self.pipelines_.append(\n",
    "                make_pipeline(deepcopy(sampler), deepcopy(estimator))\n",
    "            )\n",
    "\n",
    "        return estimator, sampler\n",
    "\n",
    "    def _boost_real(self, iboost, X, y, sample_weight, random_state):\n",
    "        \"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\n",
    "        estimator, sampler = self._make_sampler_estimator(random_state=random_state)\n",
    "\n",
    "        X_res, y_res = sampler.fit_resample(X, y)\n",
    "        sample_weight_res = _safe_indexing(sample_weight, sampler.sample_indices_)\n",
    "        estimator.fit(X_res, y_res, sample_weight=sample_weight_res)\n",
    "\n",
    "        y_predict_proba = estimator.predict_proba(X)\n",
    "\n",
    "        if iboost == 0:\n",
    "            self.classes_ = getattr(estimator, \"classes_\", None)\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "\n",
    "        y_predict = self.classes_.take(np.argmax(y_predict_proba, axis=1), axis=0)\n",
    "\n",
    "        # Instances incorrectly classified\n",
    "        incorrect = y_predict != y\n",
    "\n",
    "        # Error fraction\n",
    "        estimator_error = np.mean(np.average(incorrect, weights=sample_weight, axis=0))\n",
    "\n",
    "        # Stop if classification is perfect\n",
    "        if estimator_error <= 0:\n",
    "            return sample_weight, 1.0, 0.0\n",
    "\n",
    "        # Construct y coding as described in Zhu et al [2]:\n",
    "        #\n",
    "        #    y_k = 1 if c == k else -1 / (K - 1)\n",
    "        #\n",
    "        # where K == n_classes_ and c, k in [0, K) are indices along the second\n",
    "        # axis of the y coding with c being the index corresponding to the true\n",
    "        # class label.\n",
    "        n_classes = self.n_classes_\n",
    "        classes = self.classes_\n",
    "        y_codes = np.array([-1.0 / (n_classes - 1), 1.0])\n",
    "        y_coding = y_codes.take(classes == y[:, np.newaxis])\n",
    "\n",
    "        # Displace zero probabilities so the log is defined.\n",
    "        # Also fix negative elements which may occur with\n",
    "        # negative sample weights.\n",
    "        proba = y_predict_proba  # alias for readability\n",
    "        np.clip(proba, np.finfo(proba.dtype).eps, None, out=proba)\n",
    "\n",
    "        # Boost weight using multi-class AdaBoost SAMME.R alg\n",
    "        estimator_weight = (\n",
    "            -1.0\n",
    "            * self.learning_rate\n",
    "            * ((n_classes - 1.0) / n_classes)\n",
    "            * (y_coding * np.log(y_predict_proba)).sum(axis=1)\n",
    "        )\n",
    "\n",
    "        # Only boost the weights if it will fit again\n",
    "        if not iboost == self.n_estimators - 1:\n",
    "            # Only boost positive weights\n",
    "            sample_weight *= np.exp(\n",
    "                estimator_weight * ((sample_weight > 0) | (estimator_weight < 0))\n",
    "            )\n",
    "\n",
    "        return sample_weight, 1.0, estimator_error\n",
    "\n",
    "    def _boost_discrete(self, iboost, X, y, sample_weight, random_state):\n",
    "        \"\"\"Implement a single boost using the SAMME discrete algorithm.\"\"\"\n",
    "        estimator, sampler = self._make_sampler_estimator(random_state=random_state)\n",
    "\n",
    "        X_res, y_res = sampler.fit_resample(X, y)\n",
    "        sample_weight_res = _safe_indexing(sample_weight, sampler.sample_indices_)\n",
    "        estimator.fit(X_res, y_res, sample_weight=sample_weight_res)\n",
    "\n",
    "        y_predict = estimator.predict(X)\n",
    "\n",
    "        if iboost == 0:\n",
    "            self.classes_ = getattr(estimator, \"classes_\", None)\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "\n",
    "        # Instances incorrectly classified\n",
    "        incorrect = y_predict != y\n",
    "\n",
    "        # Error fraction\n",
    "        estimator_error = np.mean(np.average(incorrect, weights=sample_weight, axis=0))\n",
    "\n",
    "        # Stop if classification is perfect\n",
    "        if estimator_error <= 0:\n",
    "            return sample_weight, 1.0, 0.0\n",
    "\n",
    "        n_classes = self.n_classes_\n",
    "\n",
    "        # Stop if the error is at least as bad as random guessing\n",
    "        if estimator_error >= 1.0 - (1.0 / n_classes):\n",
    "            self.estimators_.pop(-1)\n",
    "            self.samplers_.pop(-1)\n",
    "            self.pipelines_.pop(-1)\n",
    "            if len(self.estimators_) == 0:\n",
    "                raise ValueError(\n",
    "                    \"BaseClassifier in AdaBoostClassifier \"\n",
    "                    \"ensemble is worse than random, ensemble \"\n",
    "                    \"can not be fit.\"\n",
    "                )\n",
    "            return None, None, None\n",
    "\n",
    "        # Boost weight using multi-class AdaBoost SAMME alg\n",
    "        estimator_weight = self.learning_rate * (\n",
    "            np.log((1.0 - estimator_error) / estimator_error) + np.log(n_classes - 1.0)\n",
    "        )\n",
    "\n",
    "        # Only boost the weights if I will fit again\n",
    "        if not iboost == self.n_estimators - 1:\n",
    "            # Only boost positive weights\n",
    "            sample_weight *= np.exp(estimator_weight * incorrect * (sample_weight > 0))\n",
    "\n",
    "        return sample_weight, estimator_weight, estimator_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31ba11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count= 1\n",
    "\n",
    "for ii in data_name:\n",
    "    data= pd.read_csv('{}.csv'.format(ii))\n",
    "    x=data.iloc[:,:-1]\n",
    "    y=data.iloc[:,-1]\n",
    "    x= sc.fit_transform(x)\n",
    "    \n",
    "\n",
    "    over_boost= OverBoostClassifier(random_state=84)\n",
    "    steps=[('model',over_boost)]\n",
    "    pipeline= Pipeline(steps=steps)\n",
    "    score = cross_validate(pipeline, x,y, cv=StratifiedKFold(5), n_jobs=-1, scoring=scores)\n",
    "    \n",
    "    df1=pd.DataFrame(score)\n",
    "    \n",
    "    x= df1.mean()*100\n",
    "    \n",
    "    gmean.loc[count-1, 'Over_Boost']= x['test_gmean']\n",
    "    roc.loc[count-1, 'Over_Boost']= x['test_roc']\n",
    "    mcc.loc[count-1, 'Over_Boost']= x['test_mcc']\n",
    "    accuracy.loc[count-1, 'Over_Boost']= x['test_accuracy']\n",
    "    sensitivity.loc[count-1, 'Over_Boost']= x['test_sensitivity']\n",
    "    \n",
    "    count= count+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b917f858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Imbalance Ratio</th>\n",
       "      <th>Over-Bagging</th>\n",
       "      <th>SMOTE-Bagging</th>\n",
       "      <th>NC</th>\n",
       "      <th>CNN</th>\n",
       "      <th>Over_Boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1.86</td>\n",
       "      <td>90.528052</td>\n",
       "      <td>89.203349</td>\n",
       "      <td>93.737384</td>\n",
       "      <td>92.174009</td>\n",
       "      <td>88.458366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vehicle2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>91.893833</td>\n",
       "      <td>92.270894</td>\n",
       "      <td>95.408171</td>\n",
       "      <td>94.623106</td>\n",
       "      <td>94.241222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vehicle1</td>\n",
       "      <td>2.90</td>\n",
       "      <td>38.654234</td>\n",
       "      <td>41.195754</td>\n",
       "      <td>52.216259</td>\n",
       "      <td>49.618697</td>\n",
       "      <td>41.996465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vehicle3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>38.468441</td>\n",
       "      <td>37.380118</td>\n",
       "      <td>46.714760</td>\n",
       "      <td>42.927883</td>\n",
       "      <td>43.568631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new-thyroid1</td>\n",
       "      <td>5.11</td>\n",
       "      <td>89.734770</td>\n",
       "      <td>89.790218</td>\n",
       "      <td>94.716721</td>\n",
       "      <td>88.927348</td>\n",
       "      <td>94.968505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ecoli2</td>\n",
       "      <td>5.44</td>\n",
       "      <td>70.440302</td>\n",
       "      <td>76.941879</td>\n",
       "      <td>77.760230</td>\n",
       "      <td>74.532264</td>\n",
       "      <td>69.667825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glass6</td>\n",
       "      <td>6.34</td>\n",
       "      <td>86.125782</td>\n",
       "      <td>86.125782</td>\n",
       "      <td>86.536234</td>\n",
       "      <td>82.338630</td>\n",
       "      <td>88.527228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yeast</td>\n",
       "      <td>8.10</td>\n",
       "      <td>75.069777</td>\n",
       "      <td>75.088067</td>\n",
       "      <td>77.426893</td>\n",
       "      <td>76.647412</td>\n",
       "      <td>73.219436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yeast3</td>\n",
       "      <td>8.10</td>\n",
       "      <td>74.197739</td>\n",
       "      <td>72.480884</td>\n",
       "      <td>77.376389</td>\n",
       "      <td>78.142842</td>\n",
       "      <td>74.653906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ecoli3</td>\n",
       "      <td>8.57</td>\n",
       "      <td>48.421703</td>\n",
       "      <td>61.540028</td>\n",
       "      <td>58.144347</td>\n",
       "      <td>54.196504</td>\n",
       "      <td>49.203359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yeast-2_vs_4</td>\n",
       "      <td>9.06</td>\n",
       "      <td>71.086574</td>\n",
       "      <td>74.842381</td>\n",
       "      <td>77.341152</td>\n",
       "      <td>77.163196</td>\n",
       "      <td>70.436949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yeast-0-2-5-6_vs_3-7-8-9</td>\n",
       "      <td>9.13</td>\n",
       "      <td>44.804678</td>\n",
       "      <td>42.042953</td>\n",
       "      <td>56.529840</td>\n",
       "      <td>52.302625</td>\n",
       "      <td>40.806849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vowel</td>\n",
       "      <td>9.98</td>\n",
       "      <td>78.580136</td>\n",
       "      <td>79.128950</td>\n",
       "      <td>68.662774</td>\n",
       "      <td>75.845021</td>\n",
       "      <td>78.494067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>led7digit-0-2-4-5-6-7-8-9_vs_1</td>\n",
       "      <td>10.95</td>\n",
       "      <td>64.587412</td>\n",
       "      <td>67.359763</td>\n",
       "      <td>67.616571</td>\n",
       "      <td>69.603815</td>\n",
       "      <td>61.675399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>glass2</td>\n",
       "      <td>11.53</td>\n",
       "      <td>26.220914</td>\n",
       "      <td>19.666700</td>\n",
       "      <td>12.456257</td>\n",
       "      <td>16.011045</td>\n",
       "      <td>20.659749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ecoli-0-1-4-7_vs_5-6</td>\n",
       "      <td>12.24</td>\n",
       "      <td>67.469267</td>\n",
       "      <td>69.524582</td>\n",
       "      <td>64.232813</td>\n",
       "      <td>67.998262</td>\n",
       "      <td>63.123457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>glass4</td>\n",
       "      <td>15.38</td>\n",
       "      <td>64.646581</td>\n",
       "      <td>53.219728</td>\n",
       "      <td>65.487155</td>\n",
       "      <td>46.772860</td>\n",
       "      <td>62.932047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ecoli4</td>\n",
       "      <td>15.75</td>\n",
       "      <td>72.775159</td>\n",
       "      <td>70.944368</td>\n",
       "      <td>66.825225</td>\n",
       "      <td>68.871590</td>\n",
       "      <td>81.977999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>page-blocks-1-3_vs_4</td>\n",
       "      <td>15.82</td>\n",
       "      <td>73.810606</td>\n",
       "      <td>73.810606</td>\n",
       "      <td>78.254182</td>\n",
       "      <td>87.461293</td>\n",
       "      <td>86.339178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abalone</td>\n",
       "      <td>16.40</td>\n",
       "      <td>33.004389</td>\n",
       "      <td>29.620776</td>\n",
       "      <td>30.738487</td>\n",
       "      <td>28.244082</td>\n",
       "      <td>31.838156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>yeast-1-4-5-8_vs_7</td>\n",
       "      <td>22.07</td>\n",
       "      <td>7.651386</td>\n",
       "      <td>6.283761</td>\n",
       "      <td>-0.517088</td>\n",
       "      <td>9.730129</td>\n",
       "      <td>13.730939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>yeast4</td>\n",
       "      <td>28.08</td>\n",
       "      <td>24.021245</td>\n",
       "      <td>37.898498</td>\n",
       "      <td>38.042700</td>\n",
       "      <td>33.986855</td>\n",
       "      <td>33.122567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>yeast128</td>\n",
       "      <td>30.53</td>\n",
       "      <td>13.004099</td>\n",
       "      <td>15.845927</td>\n",
       "      <td>10.314303</td>\n",
       "      <td>17.453955</td>\n",
       "      <td>13.823181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>winequality-red-8_vs_6</td>\n",
       "      <td>35.39</td>\n",
       "      <td>4.527559</td>\n",
       "      <td>8.286914</td>\n",
       "      <td>9.060740</td>\n",
       "      <td>9.647660</td>\n",
       "      <td>6.995889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ecoli_013vs26</td>\n",
       "      <td>39.00</td>\n",
       "      <td>-0.518999</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>36.178022</td>\n",
       "      <td>26.751248</td>\n",
       "      <td>2.350583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abalone-17_vs_7-8-9-10</td>\n",
       "      <td>39.29</td>\n",
       "      <td>10.816852</td>\n",
       "      <td>18.225739</td>\n",
       "      <td>19.227157</td>\n",
       "      <td>25.112818</td>\n",
       "      <td>41.574281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>winequality-white-3_vs_7</td>\n",
       "      <td>43.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.225360</td>\n",
       "      <td>16.786143</td>\n",
       "      <td>45.919104</td>\n",
       "      <td>39.567337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>winequality-red-8_vs_6-7</td>\n",
       "      <td>46.44</td>\n",
       "      <td>9.673974</td>\n",
       "      <td>6.447115</td>\n",
       "      <td>19.463462</td>\n",
       "      <td>21.122090</td>\n",
       "      <td>19.587363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>abalone-19_vs_10-11-12-13</td>\n",
       "      <td>51.29</td>\n",
       "      <td>-0.152859</td>\n",
       "      <td>1.757674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.593869</td>\n",
       "      <td>13.667687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>winequality-red-3_vs_5</td>\n",
       "      <td>68.00</td>\n",
       "      <td>-0.588235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>-0.889294</td>\n",
       "      <td>-1.472916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>abalone_20</td>\n",
       "      <td>72.65</td>\n",
       "      <td>8.638114</td>\n",
       "      <td>20.789613</td>\n",
       "      <td>12.340006</td>\n",
       "      <td>17.989574</td>\n",
       "      <td>42.002976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kddcup-land_vs_satan</td>\n",
       "      <td>79.45</td>\n",
       "      <td>94.097733</td>\n",
       "      <td>94.097733</td>\n",
       "      <td>97.293253</td>\n",
       "      <td>96.278499</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>abalone19</td>\n",
       "      <td>129.41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.410146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.058989</td>\n",
       "      <td>8.070764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  Imbalance Ratio  Over-Bagging  \\\n",
       "0                        wisconsin             1.86     90.528052   \n",
       "1                         vehicle2             2.88     91.893833   \n",
       "2                         vehicle1             2.90     38.654234   \n",
       "3                         vehicle3             2.99     38.468441   \n",
       "4                     new-thyroid1             5.11     89.734770   \n",
       "5                           ecoli2             5.44     70.440302   \n",
       "6                           glass6             6.34     86.125782   \n",
       "7                            yeast             8.10     75.069777   \n",
       "8                           yeast3             8.10     74.197739   \n",
       "9                           ecoli3             8.57     48.421703   \n",
       "10                    yeast-2_vs_4             9.06     71.086574   \n",
       "11        yeast-0-2-5-6_vs_3-7-8-9             9.13     44.804678   \n",
       "12                           vowel             9.98     78.580136   \n",
       "13  led7digit-0-2-4-5-6-7-8-9_vs_1            10.95     64.587412   \n",
       "14                          glass2            11.53     26.220914   \n",
       "15            ecoli-0-1-4-7_vs_5-6            12.24     67.469267   \n",
       "16                          glass4            15.38     64.646581   \n",
       "17                          ecoli4            15.75     72.775159   \n",
       "18            page-blocks-1-3_vs_4            15.82     73.810606   \n",
       "19                         abalone            16.40     33.004389   \n",
       "20              yeast-1-4-5-8_vs_7            22.07      7.651386   \n",
       "21                          yeast4            28.08     24.021245   \n",
       "22                        yeast128            30.53     13.004099   \n",
       "23          winequality-red-8_vs_6            35.39      4.527559   \n",
       "24                   ecoli_013vs26            39.00     -0.518999   \n",
       "25          abalone-17_vs_7-8-9-10            39.29     10.816852   \n",
       "26        winequality-white-3_vs_7            43.95      0.000000   \n",
       "27        winequality-red-8_vs_6-7            46.44      9.673974   \n",
       "28       abalone-19_vs_10-11-12-13            51.29     -0.152859   \n",
       "29          winequality-red-3_vs_5            68.00     -0.588235   \n",
       "30                      abalone_20            72.65      8.638114   \n",
       "31            kddcup-land_vs_satan            79.45     94.097733   \n",
       "32                       abalone19           129.41      0.000000   \n",
       "\n",
       "    SMOTE-Bagging         NC        CNN  Over_Boost  \n",
       "0       89.203349  93.737384  92.174009   88.458366  \n",
       "1       92.270894  95.408171  94.623106   94.241222  \n",
       "2       41.195754  52.216259  49.618697   41.996465  \n",
       "3       37.380118  46.714760  42.927883   43.568631  \n",
       "4       89.790218  94.716721  88.927348   94.968505  \n",
       "5       76.941879  77.760230  74.532264   69.667825  \n",
       "6       86.125782  86.536234  82.338630   88.527228  \n",
       "7       75.088067  77.426893  76.647412   73.219436  \n",
       "8       72.480884  77.376389  78.142842   74.653906  \n",
       "9       61.540028  58.144347  54.196504   49.203359  \n",
       "10      74.842381  77.341152  77.163196   70.436949  \n",
       "11      42.042953  56.529840  52.302625   40.806849  \n",
       "12      79.128950  68.662774  75.845021   78.494067  \n",
       "13      67.359763  67.616571  69.603815   61.675399  \n",
       "14      19.666700  12.456257  16.011045   20.659749  \n",
       "15      69.524582  64.232813  67.998262   63.123457  \n",
       "16      53.219728  65.487155  46.772860   62.932047  \n",
       "17      70.944368  66.825225  68.871590   81.977999  \n",
       "18      73.810606  78.254182  87.461293   86.339178  \n",
       "19      29.620776  30.738487  28.244082   31.838156  \n",
       "20       6.283761  -0.517088   9.730129   13.730939  \n",
       "21      37.898498  38.042700  33.986855   33.122567  \n",
       "22      15.845927  10.314303  17.453955   13.823181  \n",
       "23       8.286914   9.060740   9.647660    6.995889  \n",
       "24      33.333333  36.178022  26.751248    2.350583  \n",
       "25      18.225739  19.227157  25.112818   41.574281  \n",
       "26      -0.225360  16.786143  45.919104   39.567337  \n",
       "27       6.447115  19.463462  21.122090   19.587363  \n",
       "28       1.757674   0.000000  -0.593869   13.667687  \n",
       "29       0.000000  -0.294118  -0.889294   -1.472916  \n",
       "30      20.789613  12.340006  17.989574   42.002976  \n",
       "31      94.097733  97.293253  96.278499  100.000000  \n",
       "32      -0.410146   0.000000  -0.058989    8.070764  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ca1448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('ibrf_other_models_results.xlsx') as writer:  \n",
    "         gmean.to_excel(writer, sheet_name='gmean')\n",
    "         mcc.to_excel(writer, sheet_name='mcc')\n",
    "         roc.to_excel(writer, sheet_name='roc')\n",
    "         accuracy.to_excel(writer, sheet_name='accuracy')\n",
    "         sensitivity.to_excel(writer, sheet_name='sensitivity')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
